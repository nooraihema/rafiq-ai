// context_tracker.js v1.0 - The Short-Term Memory Core
// This engine's sole purpose is to maintain and analyze the immediate context of a conversation.
// It is the AI's working memory.

import { DEBUG } from './config.js';

const MAX_HISTORY = 5; // The number of turns to remember for short-term context.

/**
 * A class representing the conversational context for a single user.
 */
export class ContextTracker {
    constructor(userProfile) {
        this.userId = userProfile.id;
        // We initialize the context from the user's saved shortMemory.
        this.history = userProfile.shortMemory || [];
    }

    /**
     * Adds the latest turn (fingerprint and response) to the history.
     * @param {object} fingerprint - The psychological fingerprint of the user's message.
     * @param {object} responsePayload - The response generated by the composition engine.
     */
    addTurn(fingerprint, responsePayload) {
        this.history.push({
            timestamp: new Date().toISOString(),
            user_fingerprint: fingerprint,
            ai_response: responsePayload
        });

        // Keep the history from growing too large.
        if (this.history.length > MAX_HISTORY) {
            this.history.shift(); // Remove the oldest entry
        }
    }

    /**
     * Analyzes the recent history to extract valuable meta-information.
     * This is where the magic of short-term memory happens.
     * @returns {object} A summary of the current conversational state.
     */
    analyzeState() {
        const state = {
            recent_concepts: new Set(),
            recent_needs: new Set(),
            recent_recipes: new Set(),
            is_stuck_in_loop: false,
            emotional_trend: 'stable' // 'improving', 'worsening', 'stable'
        };

        if (this.history.length < 2) {
            return state; // Not enough data to analyze yet.
        }

        // Gather concepts and needs from the last few turns
        this.history.forEach(turn => {
            if (turn.user_fingerprint) {
                turn.user_fingerprint.relatedConcepts.forEach(c => state.recent_concepts.add(c));
                state.recent_needs.add(turn.user_fingerprint.inferredNeed);
            }
            if (turn.ai_response && turn.ai_response.recipe) {
                turn.ai_response.recipe.forEach(r => state.recent_recipes.add(r));
            }
        });

        // Check for loops (e.g., repeating the same need 3 times in a row)
        const lastThreeNeeds = this.history.slice(-3).map(t => t.user_fingerprint?.inferredNeed);
        if (lastThreeNeeds.length === 3 && lastThreeNeeds.every(need => need === lastThreeNeeds[0])) {
            state.is_stuck_in_loop = true;
        }
        
        // A simple emotional trend analysis
        const firstIntensity = this.history[0].user_fingerprint?.primaryEmotion.intensity || 0.5;
        const lastIntensity = this.history[this.history.length - 1].user_fingerprint?.primaryEmotion.intensity || 0.5;

        if(lastIntensity < firstIntensity - 0.2) {
            state.emotional_trend = 'improving';
        } else if (lastIntensity > firstIntensity + 0.2) {
            state.emotional_trend = 'worsening';
        }

        if (DEBUG) console.log(`ðŸ“ˆ Context State Analyzed:`, { ...state, recent_concepts: [...state.recent_concepts] });

        return state;
    }

    /**
     * Prepares the short-term memory to be saved back to the user's profile.
     * @returns {object[]} The history array.
     */
    serialize() {
        return this.history;
    }
}
